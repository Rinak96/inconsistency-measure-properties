{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>inconsistency-measurer</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Imports </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntProgress\n",
    "import gurobipy as gp\n",
    "import numpy as numpy\n",
    "from gurobipy import GRB\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from subprocess import PIPE, run\n",
    "import pandasql as psql\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import ViolationsAlgorithm as vio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dynamic_queries(constraintSets,df):\n",
    "    \"\"\"\n",
    "    build_dynamic_queries - generates dynamic queries based on the given constraints.\n",
    "    This function will generate two queries:\n",
    "    1. unionOfAllTuples - returns the ids of the tuples participating in a violation of the constraints.\n",
    "    2. unionOfAllPairs - returns pairs (i1,i2) of ids of tuples that jointly violate the constraints.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    constraintSets : set of strings\n",
    "        each string represents a constraint from the dcs file\n",
    "    df : dataframe\n",
    "        the database frame\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of three string values:\n",
    "        unionOfAllTuples, unionOfAllPairs are the generated queries\n",
    "        allColumns is a string consisting of all column names seperated by ','\n",
    "    \"\"\" \n",
    "    \n",
    "    allColumns = ' '.join([str(elem) for elem in df.columns.values.tolist()]).replace(' ',',')\n",
    "\n",
    "    #Additional conditions for the queries, in order to ignore missing values in the database\n",
    "    count = 1\n",
    "    columnsT1 = \"\"\n",
    "    for col in df.columns: \n",
    "        columnsT1 += \"t1.\"+col\n",
    "        if count!=len(df.columns) :\n",
    "            columnsT1+= ' IS NOT NULL AND '\n",
    "        count+=1\n",
    "    columnsT1+=\" IS NOT NULL \"\n",
    "    columnsT2 = columnsT1.replace('t1','t2')\n",
    "\n",
    "    count = 0\n",
    "    for con in constraintSets: \n",
    "        if count == 0:\n",
    "            unionOfAllPairs = \" SELECT t1.rowid as t1ctid ,t2.rowid as t2ctid FROM df t1,df t2 WHERE \"\n",
    "            unionOfAllTuples = \" SELECT * FROM df t1,df t2 WHERE \" \n",
    "        else : \n",
    "            unionOfAllPairs += \" UNION SELECT t1.rowid as t1ctid ,t2.rowid as t2ctid FROM df t1,df t2 WHERE \"\n",
    "            unionOfAllTuples += \" UNION SELECT * FROM df t1,df t2 WHERE \"\n",
    "            \n",
    "        rep = {\" \": \"_\", \"&\": \" and \",\"not(\":\"\",\")\":\"\"} \n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        con1 = pattern.sub(lambda m: rep[re.escape(m.group(0))], con)     \n",
    "\n",
    "        # in case the constraint refers to a single tuple\n",
    "        if \"t2\" not in con: \n",
    "            con1 = re.sub(r'(t1.*?)t1', r'\\1t2', con1, 1)\n",
    "            unionOfAllPairs += con1 +\" and t1.ROWID==t2.ROWID and (\"+columnsT1+\")\"\n",
    "            unionOfAllTuples += con1 +\" and t1.ROWID==t2.ROWID and (\"+columnsT1+\")\"\n",
    "        else:\n",
    "            unionOfAllPairs += con1 +\" and t1.ROWID!=t2.ROWID and (\"+columnsT1+\" and \"+columnsT2+\")\"\n",
    "            unionOfAllTuples += con1 +\" and t1.ROWID!=t2.ROWID and (\"+columnsT1+\" and \"+columnsT2+\")\"\n",
    "        count+=1\n",
    "        \n",
    "    return unionOfAllTuples,unionOfAllPairs,allColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Find all the iconsistencies in the database for a given set of constraints</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraints_check(df,constraintSets, allColumns, unionOfAllTuples, unionOfAllPairs):\n",
    "    \"\"\"\n",
    "    constraints_check - runs the dynamic queries that have been generated on the database.\n",
    "    This function will run two queries:\n",
    "    1. unionOfAllTuples - returns the ids of the tuples participating in a violation of the constraints.\n",
    "    2. unionOfAllPairs - returns pairs (i1,i2) of ids of tuples that jointly violate the constraints.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    constraintSets : set of strings\n",
    "        each string represents a constraint from the dcs file\n",
    "    unionOfAllTuples : string\n",
    "    unionOfAllPairs : string    \n",
    "    df : dataframe\n",
    "        the database frame\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of two strings and two double variables:\n",
    "        sdfcWithRep, sdfcNoRep are the results of the unionOfAllPairs and unionOfAllTuples queries, respectively.\n",
    "        end1-start, end2-start2 are the running times the queries.\n",
    "    \"\"\"     \n",
    "    \n",
    "    # finds the pairs of tuples that jointly violate a constraint\n",
    "    start = time.time()    \n",
    "    violatingPairs =  psql.sqldf(\"SELECT DISTINCT * FROM (SELECT CASE WHEN t1ctid <= t2ctid THEN t1ctid ELSE t2ctid END AS id1,CASE WHEN t1ctid <= t2ctid THEN t2ctid ELSE t1ctid END AS id2 FROM (\"+unionOfAllPairs+\")AS A)AS B\")\n",
    "    end1 = time.time()\n",
    "    \n",
    "    # finds the tuples that participate in a violation\n",
    "    start2 = time.time()\n",
    "    violatingTuples = set()\n",
    "    for pair in violatingPairs.values:\n",
    "        for item in pair:\n",
    "            violatingTuples.add(item)\n",
    "    end2 = time.time()\n",
    "    \n",
    "    return violatingPairs, violatingTuples, end1-start, end2-start2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Functions for computing the measurments</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_measurer_I_D(uniquePairsDf):\n",
    "    \"\"\"\n",
    "    first_measurer_I_D: computes the drastic inconsistency measure I_d.\n",
    "    This function checks whether the result of the query that finds the violating pairs of tuples is empty.\n",
    "    In case it is empty ,the database is consistent. Otherwise, it is inconsistent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uniquePairsDf : dataframe\n",
    "        the result of the query that finds all pairs of tuples that jointly violate a constraint.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        0 if database is consistent, and 1 otherwise\n",
    "    \"\"\"  \n",
    "    if len(uniquePairsDf):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def second_measurer_I_MI(uniquePairsDf):\n",
    "    \"\"\"\n",
    "    second_measurer_I_MI: computes the measure I_MI that counts the minimal inconsistent subsets of the database.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uniquePairsDf : dataframe\n",
    "        the result of the query that finds all pairs of tuples that jointly violate a constraint.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        number of pairs of tuples that jointly violate a constraint.\n",
    "    \"\"\" \n",
    "    \n",
    "    return len(uniquePairsDf)\n",
    "\n",
    "def third_measurer_I_P(uniqueTuplesDf):\n",
    "    \"\"\"\n",
    "    third_measurer_I_P: computes the measure I_P that counts the number of problematic tuples \n",
    "    (tuples participating in a violation of the constraints).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uniqueTuplesDf : dataframe\n",
    "        the result of the query that finds all tuples that particiapte in a violation.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        number of tuples participating in a violation of the constraints.\n",
    "    \"\"\" \n",
    "    \n",
    "    return len(uniqueTuplesDf)\n",
    "\n",
    "def fourth_measurer_I_R(uniquePairsDf):\n",
    "    \"\"\"\n",
    "    fourth_measurer_I_R: computes the measure I_R that is based on the minimal number of tuples that should\n",
    "    be removed from the database for the constraints to hold.\n",
    "    The measure is computed via an ILP and the Gurobi optimizer is used to solve the ILP.\n",
    "    \n",
    "    - There is a binary variable x for every tuple in the database.\n",
    "    - The constraints are of the form x + y >= 1 where x and y represent two tuples that jointly vioalte a constraint.\n",
    "    - The objective function is to minimize the sum of all x's.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uniquePairsDf : dataframe\n",
    "        the result of the query that finds all pairs of tuples that jointly violate a constraint.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of two int variables:\n",
    "        database_measurer.objVal is the minimal number of tuples that should be removed for the constraints to hold.\n",
    "        end1 - start is the running time of the function.\n",
    "    \"\"\" \n",
    "    \n",
    "    start = time.time()\n",
    "    rows_violations = uniquePairsDf.values\n",
    "    varsDict2 = {}\n",
    "    database_measurer = gp.Model('Minimal deletions of tuples')\n",
    "    database_measurer.setParam('OutputFlag', 0)  # do not show any comments on the screen \n",
    "    \n",
    "    # variables\n",
    "    for i in rows_violations :\n",
    "        varsDict2[i[0]] = database_measurer.addVar(vtype=GRB.BINARY, name=\"x\")\n",
    "        varsDict2[i[1]] = database_measurer.addVar(vtype=GRB.BINARY, name=\"x\")\n",
    "    \n",
    "    # constraints\n",
    "    for i in rows_violations :\n",
    "        database_measurer.addConstr(varsDict2[i[0]]+varsDict2[i[1]]>=1, name='con')\n",
    "    vars= []\n",
    "    for i in varsDict2:\n",
    "        vars.append(varsDict2[i])\n",
    "        \n",
    "    # objective function    \n",
    "    database_measurer.setObjective(sum(vars), GRB.MINIMIZE)\n",
    "    \n",
    "    opt = database_measurer.optimize()\n",
    "    end1 = time.time()\n",
    "    return database_measurer.objVal , end1 - start\n",
    "\n",
    "def fifth_measurer_I_lin_R(uniquePairsDf):\n",
    "    \"\"\"\n",
    "    fifth_measurer_I_lin_R: computes the measure I^lin_R that is the linear relaxation of the ILP used for computing\n",
    "    the measure I_R.\n",
    "    \n",
    "    - There is a variable x for every tuple in the database such that 0<=x<=1.\n",
    "    - The constraints are of the form x + y >= 1 where x and y represent two tuples that jointly vioalte a constraint.\n",
    "    - The objective function is to minimize the sum of all x's.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uniquePairsDf : dataframe\n",
    "        the result of the query that finds all pairs of tuples that jointly violate a constraint.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of two int variables:\n",
    "        database_measurer.objVal is the result of the LP.\n",
    "        end2 - start is the running time of the function.\n",
    "    \"\"\" \n",
    "    \n",
    "    start = time.time()\n",
    "    rows_violations = uniquePairsDf.values\n",
    "    varsDict2 = {}\n",
    "    database_measurer = gp.Model('Minimal deletions of tuples relaxed')\n",
    "    database_measurer.setParam('OutputFlag', 0)  # do not show any comments on the screen \n",
    "    \n",
    "    # variables\n",
    "    for i in rows_violations :\n",
    "        varsDict2[i[0]] = database_measurer.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "        varsDict2[i[1]] = database_measurer.addVar(lb=0, ub=1, vtype=GRB.CONTINUOUS, name=\"x\")\n",
    "    \n",
    "    # constraints\n",
    "    for i in rows_violations :\n",
    "        database_measurer.addConstr(varsDict2[i[0]]+varsDict2[i[1]]>=1, name='con')\n",
    "    vars= []\n",
    "    for i in varsDict2:\n",
    "        vars.append(varsDict2[i])\n",
    "    \n",
    "    # objective function\n",
    "    database_measurer.setObjective(sum(vars), GRB.MINIMIZE)\n",
    "    \n",
    "    opt = database_measurer.optimize()\n",
    "    end2 = time.time()\n",
    "    return database_measurer.objVal , end2 -start\n",
    "\n",
    "def sixth_measurer_I_MC(fullPath, uniquePairsDf):\n",
    "    \"\"\"\n",
    "    sixth_measurer_I_MC: computes the measure I_MC that counts the maximal consistent subsets (i.e., repairs),\n",
    "    which are also the maximal independent sets of the conflict graph wherein nodes represent tuples\n",
    "    and edges represent pairs of tuples that jointly violate a constraint.\n",
    "    This function generates the complement of the conflict graph (where edges represent pairs of tuples that do not \n",
    "    jointly violate any constraint). Then, an algorithm for enumearing maximal cliques in a graph is invoked.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fullPath : string\n",
    "        the path of the directory where the graph will be generated\n",
    "    uniquePairsDf : dataframe\n",
    "         the result of the query that finds all pairs of tuples that jointly violate a constraint.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of two int variables:\n",
    "        result_output is the number of maximal cliques the algorithm generated.\n",
    "        end - start is the function running time of the function.\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    rows_violations = uniquePairsDf.values\n",
    "    num_of_rows = len(df.index)\n",
    "\n",
    "    varsDict = {}\n",
    "    for i in range(num_of_rows):\n",
    "        varsDict[i] = num_of_rows - 1 - numpy.count_nonzero(rows_violations == i+1) \n",
    "    \n",
    "    # cart_prod contains all possible edges in the graph\n",
    "    all_rows1 = list(range(0, num_of_rows)) \n",
    "    all_rows2 = list(range(0, num_of_rows)) \n",
    "    cart_prod = [(a,b,1) for a in all_rows1 for b in all_rows2]\n",
    "    rows_violations = rows_violations - 1\n",
    "    \n",
    "    # for each pair that violates the constraints turn off the valid bit\n",
    "    for i in rows_violations:\n",
    "        lst = list(cart_prod[i[0]*num_of_rows+i[1]])\n",
    "        lst[2] = 0\n",
    "        cart_prod[i[0]*num_of_rows+i[1]] = tuple(lst)\n",
    "        lst = list(cart_prod[i[1]*num_of_rows+i[0]])\n",
    "        lst[2] = 0\n",
    "        cart_prod[i[1]*num_of_rows+i[0]] = tuple(lst)\n",
    "    \n",
    "    graphFileName = fullPath + '/graph.nde'\n",
    "\n",
    "    f = open(graphFileName, \"w+\")\n",
    "    \n",
    "    # construct the nodes with their degrees [degree = number of rows - 1 - number of appereances in rows_vioalations]\n",
    "    f.write(str(num_of_rows))\n",
    "    for k, v in varsDict.items():\n",
    "        f.write('\\n'+ str(k) + ' '+ str(v))\n",
    "    \n",
    "    # construct the edges \n",
    "    for i in cart_prod:\n",
    "        if i[2] and i[0]!=i[1]:\n",
    "            f.write('\\n'+str(i[0]) + ' '+ str(i[1]))\n",
    "            lst = list(cart_prod[i[1]*num_of_rows+i[0]])\n",
    "            lst[2] = 0\n",
    "            cart_prod[i[1]*num_of_rows+i[0]] = tuple(lst)\n",
    "    \n",
    "    f.close()    \n",
    "    \n",
    "    # locate the full path to the graph and text_ui\n",
    "    buildFullPath = os.path.abspath(\"parallel_enum/build/text_ui\")\n",
    "    graphFullPath = os.path.abspath(graphFileName)\n",
    "    \n",
    "    # invoke the algorithm for enumerating maximal cliques with the graph as a parameter\n",
    "    result = run(buildFullPath+' -system=\"clique\" '+ graphFullPath,shell=True,capture_output=True)\n",
    "    results = \"\"\n",
    "    results = result.stdout\n",
    "    result_output = int((str(results.split()[14]).replace('b',\"\").replace(\"'\",\"\")))\n",
    "    \n",
    "    end = time.time()\n",
    "    return result_output, end - start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Function to run measurments: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTest(testDirectoryPath, timesToRunTheTest, measuresToRun, singleIteration):\n",
    "    \"\"\"\n",
    "    runTest - the main function that computes the measures specified by the user on the given database.\n",
    "    \n",
    "    If singleIteration is true, then all the measures will be computed once on the given database.\n",
    "    \n",
    "    Otherwise, the function will run a simulation that generates random violations in the given database, and\n",
    "    computes, after each iteration (i.e., after each change in the database), the values of all the measures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    testDirectoryPath : string\n",
    "        the name of the folder containing the database\n",
    "    timesToRunTheTest : int\n",
    "        if singleIteration is false, this is the number of iteration in the simulation.\n",
    "    measuresToRun : dictionary\n",
    "        a dictionary in which the measures are the keys and true/false are the values.\n",
    "        The function will compute the measures for which the value is true.\n",
    "    singleIteration : bool\n",
    "        true if the measures should be computed once on the given database, and false for a simulation.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Generate a chart for each measure where the y axis is the value of the measure and the x axis is the \n",
    "    iteration number. The charts will be saved under the folder containing the database.\n",
    "    \n",
    "    The files \"Running_Time.txt\" and \"All_results.txt\" contain the average running time of each maasure and\n",
    "    all the results of the execution, respectively.\n",
    "    \n",
    "    \"\"\"\n",
    "    global df\n",
    "    # messages at start\n",
    "    if not singleIteration:\n",
    "        print('Test '+testDirectoryPath+' : running ' + str(timesToRunTheTest) + ' iterations; startTime:' + str(time.time()))\n",
    "    else:\n",
    "        print('Test '+testDirectoryPath+' ; startTime:' + str(time.time()))\n",
    "\n",
    "    # constracting paths for the results     \n",
    "    resultsDirectoryPath = '/' + str(time.time()) + '_results'\n",
    "    fullPath = 'Data/'+ testDirectoryPath + resultsDirectoryPath\n",
    "    if (not os.path.exists(fullPath)):\n",
    "        os.makedirs(fullPath);\n",
    "    runningTimesFileName = fullPath +'/Running_Time.txt'\n",
    "    allResultsFileName = fullPath +'/All_results.txt'\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # load the csv file and generate a list of constraints\n",
    "    df = pd.read_csv('Data/'+ testDirectoryPath + '/' + \"inputDB.csv\", keep_default_na=False, na_values=['-1.#IND', '1.#QNAN', '1.#IND', '-1.#QNAN', '#N/A N/A', '#N/A', 'N/A', 'n/a','', '#NA', 'NULL','null', 'NaN', '-NaN', 'nan', '-nan', ''] , header=0)\n",
    "    constraints_raw = open('Data/'+ testDirectoryPath+'/dcs.txt', 'r')\n",
    "    constraints = [line.strip() for line in constraints_raw.readlines()]\n",
    "    constraints = [x.replace(' ', '_') for x in constraints] #in case the columns names include spaces\n",
    "\n",
    "    pd.options.mode.chained_assignment = None \n",
    "    \n",
    "    # in case the column names include spaces\n",
    "    allColumns = {}\n",
    "    for col in df.columns: \n",
    "        allColumns[col] = col.replace(' ','_')\n",
    "    df = df.rename(columns=allColumns)\n",
    "    \n",
    "    # initializations\n",
    "    exes,measurments1,measurments2,measurments3,measurments4,measurments5,measurments6 = [],[],[],[],[],[],[]\n",
    "    sum2,sum3,sum4,sum5,sum6 = 0,0,0,0,0\n",
    "    \n",
    "    # construct the dynamic queries which will be used for detecting violations in the database\n",
    "    allConstraints = build_dynamic_queries(constraints,df)\n",
    "    allColumns = allConstraints[2]  \n",
    "    \n",
    "    # calculations for the first stage - the database should be consistent\n",
    "    exes.append(0)\n",
    "    sdfc = constraints_check(df,constraints, allColumns, allConstraints[0], allConstraints[1])\n",
    "    if (measuresToRun[\"I_D\"]):\n",
    "        measurments1.append(first_measurer_I_D(sdfc[0]))\n",
    "    if (measuresToRun[\"I_MI\"]):\n",
    "        measurments2.append(second_measurer_I_MI(sdfc[0]))\n",
    "    if (measuresToRun[\"I_P\"]):\n",
    "        measurments3.append(third_measurer_I_P(sdfc[1]))\n",
    "    if (measuresToRun[\"I_R\"]):    \n",
    "        measurments4.append(fourth_measurer_I_R(sdfc[0])[0])\n",
    "    if (measuresToRun[\"I_lin_R\"]): \n",
    "        measurments5.append(fifth_measurer_I_lin_R(sdfc[0])[0])\n",
    "    if (measuresToRun[\"I_MC\"]):\n",
    "        measurments6.append(sixth_measurer_I_MC(fullPath, sdfc[0])[0])\n",
    "    \n",
    "    # progress bar\n",
    "    f = IntProgress(min = 1, max = timesToRunTheTest,description='Computing...',bar_style='success')\n",
    "    display(f)\n",
    "    \n",
    "    # in case the user wishes to run the violations algorithm and introduce random violations in the database    \n",
    "    if not singleIteration:    \n",
    "        for x in range(1, timesToRunTheTest):\n",
    "            global t1,t2\n",
    "            f.value += 1\n",
    "            time.sleep(.1)\n",
    "            \n",
    "            # choose two tuples randomly\n",
    "            sample = df.sample(n=2)\n",
    "            t1 = sample.iloc[0]\n",
    "            t2 = sample.iloc[1]\n",
    "        \n",
    "            # clean constraint from excessive chars\n",
    "            constraintSetRaw = random.choice(constraints)\n",
    "            constraintSet = constraintSetRaw[4:-1].split('&')\n",
    "            constraintSet = [re.split('(!=|>=|<=|>|<|=)', i) for i in constraintSet]\n",
    "            \n",
    "            # in case the constraint refers to a single tuple\n",
    "            if \"t2\" not in constraintSet:\n",
    "                t2 = t1\n",
    "                \n",
    "            # generate violations using the fittingViolationAlgorithm in ViolationsAlgorithm.py\n",
    "            t = vio.fittingViolationAlgorithm(constraintSet,df,t1,t2)\n",
    "            vio.updateTable(df,t[0],t[1],sample)\n",
    "\n",
    "            # calcuate the queries needed for the measures\n",
    "            sdfc = constraints_check(df,constraints, allColumns, allConstraints[0], allConstraints[1])\n",
    "            exes.append(x)\n",
    "\n",
    "            if (measuresToRun[\"I_D\"]):\n",
    "                measurments1.append(first_measurer_I_D(sdfc[0]))\n",
    "\n",
    "            if (measuresToRun[\"I_MI\"]):\n",
    "                measurments2.append(second_measurer_I_MI(sdfc[0]))\n",
    "                sum2 += sdfc[2]\n",
    "\n",
    "            if (measuresToRun[\"I_P\"]):\n",
    "                measurments3.append(third_measurer_I_P(sdfc[1]))\n",
    "                sum3 += sdfc[3]\n",
    "\n",
    "            if (measuresToRun[\"I_R\"]):    \n",
    "                res1 = fourth_measurer_I_R(sdfc[0])\n",
    "                measurments4.append(res1[0])\n",
    "                sum4 += res1[1]\n",
    "\n",
    "            if (measuresToRun[\"I_lin_R\"]): \n",
    "                res2 = fifth_measurer_I_lin_R(sdfc[0])\n",
    "                measurments5.append(res2[0])\n",
    "                sum5 += res2[1]\n",
    "\n",
    "            if (measuresToRun[\"I_MC\"]):\n",
    "                res3 = sixth_measurer_I_MC(fullPath, sdfc[0])\n",
    "                measurments6.append(res3[0])\n",
    "                sum6 += res3[1]\n",
    "    \n",
    "    # messages at finish\n",
    "    print('Test '+testDirectoryPath+' : runTime = ' + str(time.time()))\n",
    "    print('Test '+testDirectoryPath+' finished, preparing the results.')\n",
    "    \n",
    "    f_times   = open(runningTimesFileName, \"a+\")\n",
    "    f_results = open(allResultsFileName,\"a+\")\n",
    "    \n",
    "    if (measuresToRun[\"I_D\"]):\n",
    "        plt.scatter(exes, measurments1, c='r')\n",
    "        plt.title('Drastic inconsistency value I_D:')\n",
    "        plt.ylabel('results')\n",
    "        plt.xlabel('number of changes')\n",
    "        plt.savefig('Data/'+ testDirectoryPath + resultsDirectoryPath + '/I_D.jpg', dpi=300)\n",
    "        plt.clf()\n",
    "\n",
    "    if (measuresToRun[\"I_MI\"]):\n",
    "        plt.scatter(exes, measurments2, c='b')\n",
    "        plt.title('Minimal inconsistent subsets of D I_MI:')\n",
    "        plt.ylabel('results')\n",
    "        plt.xlabel('number of changes')\n",
    "        plt.savefig('Data/'+ testDirectoryPath + resultsDirectoryPath + '/I_MI.jpg', dpi=300) \n",
    "        f_times.write(\"AVG for I_MI: \")\n",
    "        f_times.write(str(float(sum2/timesToRunTheTest)))\n",
    "        f_results.write(\"I_MI results: \")\n",
    "        f_results.write(str(measurments2))\n",
    "        plt.clf()\n",
    "\n",
    "    if (measuresToRun[\"I_P\"]):\n",
    "        plt.scatter(exes, measurments3, c='g')\n",
    "        plt.title('Problematic facts I_P:')\n",
    "        plt.ylabel('results')\n",
    "        plt.savefig('Data/'+ testDirectoryPath + resultsDirectoryPath + '/I_P.jpg', dpi=300)\n",
    "        f_times.write(\"\\nAVG for I_P: \")\n",
    "        f_times.write(str(float(sum3/timesToRunTheTest))) \n",
    "        f_results.write(\"\\nI_P results: \")\n",
    "        f_results.write(str(measurments3))\n",
    "        plt.clf()\n",
    "\n",
    "    if (measuresToRun[\"I_R\"]):\n",
    "        plt.scatter(exes, measurments4, c='y')\n",
    "        plt.title('Minimal cost of a sequence of operations that repairs the database I_R:')\n",
    "        plt.ylabel('results')\n",
    "        plt.xlabel('number of changes')\n",
    "        plt.savefig('Data/'+ testDirectoryPath + resultsDirectoryPath + '/I_R.jpg', dpi=300)  \n",
    "        f_times.write(\"\\nAVG for I_R: \")\n",
    "        f_times.write(str(float((sum4+sum2)/timesToRunTheTest)))\n",
    "        f_results.write(\"\\nI_R results: \")\n",
    "        f_results.write(str(measurments4))\n",
    "        plt.clf()\n",
    "\n",
    "    if (measuresToRun[\"I_lin_R\"]):\n",
    "        plt.scatter(exes, measurments5, c='pink')\n",
    "        plt.title('Linear relaxation of the fourth measurer I_lin_R:')\n",
    "        plt.ylabel('results')\n",
    "        plt.xlabel('number of changes')\n",
    "        plt.savefig('Data/'+ testDirectoryPath + resultsDirectoryPath + '/I_lin_R.jpg', dpi=300)  \n",
    "        f_times.write(\"\\nAVG for I_lin_R: \")\n",
    "        f_times.write(str(float((sum5+sum2)/timesToRunTheTest)))\n",
    "        f_results.write(\"\\nI_lin_R results: \")\n",
    "        f_results.write(str(measurments5))\n",
    "        plt.clf()\n",
    "\n",
    "    if (measuresToRun[\"I_MC\"]):\n",
    "        plt.scatter(exes, measurments6, c='purple')\n",
    "        plt.title('Maximal cliques I_MC:')\n",
    "        plt.ylabel('results')\n",
    "        plt.xlabel('number of changes')\n",
    "        plt.savefig('Data/'+ testDirectoryPath + resultsDirectoryPath + '/I_MC.jpg', dpi=300)  \n",
    "        f_times.write(\"\\nAVG for I_MC: \")\n",
    "        f_times.write(str(float((sum6+sum2)/timesToRunTheTest)))\n",
    "        f_results.write(\"\\nI_MC results: \")\n",
    "        f_results.write(str(measurments6))\n",
    "        plt.clf()\n",
    "\n",
    "    end = time.time()\n",
    "    f_times.write(\"\\ntotal time \")\n",
    "    f_times.write(str(end - start))\n",
    "\n",
    "    f_times.write(\"\\n---\\n\")\n",
    "    f_results.write(\"\\n---\\n\")\n",
    "\n",
    "    f_times.close()\n",
    "    f_results.close()\n",
    "\n",
    "    print('End of test '+testDirectoryPath + '; total time = ' + str(end - start))\n",
    "    print('\\033[1m'+\"Computation finished, outputs can be found in \"+'Data/'+ testDirectoryPath + resultsDirectoryPath +'\\n \\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMeasurers(databasesNamesToRun,IterationsNum,measurments,selected_data,singleIteration):\n",
    "    \"\"\"\n",
    "    runMeasurers - processes the data obtained by HelloNewUser and runs the function runTest\n",
    "    on each of the databases specified by the user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    databasesNamesToRun : list of strings\n",
    "        list of the databases names which the user specified\n",
    "    IterationsNum : int\n",
    "        if singleIteration is false, this is the number of iteration in the simulation.\n",
    "    measurments : dictionary\n",
    "        a dictionary in which the measures are the keys and the values are boolean.\n",
    "    selected_data : list of strings\n",
    "        a list of the measurments which were chosen by the user    \n",
    "    singleIteration : bool\n",
    "        true if the measures should be computed once on the given database, and false for a simulation.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    none\n",
    "    \"\"\" \n",
    "\n",
    "    databasesNamesToRun = re.split(',',databasesNamesToRun)\n",
    "    for n in databasesNamesToRun:\n",
    "        n = n.replace(\"'\",\"\")\n",
    "    \n",
    "    validMeasurments = []\n",
    "    for m in selected_data:\n",
    "        measurments[m] = True;\n",
    "        validMeasurments.append(m)\n",
    "            \n",
    "    print('---')\n",
    "    print('Starting tests ' + str(databasesNamesToRun) +' from database inputDB.csv \\nwith the following measurers: '+ str(validMeasurments)+ '; iterationsNum = ' + str(IterationsNum))\n",
    "    print('---')\n",
    "\n",
    "    for testName in databasesNamesToRun:\n",
    "        runTest(testName, int(IterationsNum), measurments, singleIteration)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HelloNewUser():\n",
    "    \"\"\"\n",
    "    HelloNewUser - receives the input from the user and processes it in order to call the \n",
    "    runMeasurers function with the parameters the user has specified \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    none\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    none\n",
    "    \"\"\"\n",
    "    \n",
    "    #defaults\n",
    "    singleIteration = True\n",
    "    IterationsNum = \"1\"\n",
    "    \n",
    "    print('\\033[1m'+\"Welcome to the inconsistency measurer\\n\\n\"+'\\033[0m')\n",
    "    \n",
    "    databasesNamesToRun = input(\"Please specify the databases you wish to compute the measures on (seperated by ',')\\nThe databases included are: Adult,Airport,Flight,Food,Hospital,Stock,Tax,Voters\\n\")\n",
    "    \n",
    "    print(\"\\nDo you wish to run a simulation that introduces random violations in the database? [y/n]\")\n",
    "    default2 = widgets.HTML(value=\"<i>Default value is: y</i>\")\n",
    "    display(default2)\n",
    "    violations = input()\n",
    "    \n",
    "    # in case the user wishes to run the violations algorithm \n",
    "    if violations == \"y\" or violations != \"n\":\n",
    "        singleIteration = False\n",
    "        print(\"\\nPlease specify the number of iterations of the simulation\")\n",
    "        default1 = widgets.HTML(value=\"<i>Default value is: 100</i>\")\n",
    "        display(default1)\n",
    "        IterationsNum = int(input() or \"100\")\n",
    "        \n",
    "    # each checked measurer will appear in the measurments list as 'True'\n",
    "    print(\"\\nPlease choose the measures you wish to compute: \")\n",
    "    measurments = {\"I_D\":False, \"I_MI\":False, \"I_P\":False, \"I_R\":False, \"I_lin_R\":False, \"I_MC\":False}\n",
    "    names = []\n",
    "    checkbox_objects = []\n",
    "    \n",
    "    for key in measurments:\n",
    "        checkbox_objects.append(widgets.Checkbox(value=False, description=key))\n",
    "        names.append(key)\n",
    "\n",
    "    arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "\n",
    "    ui = widgets.VBox(children=checkbox_objects)\n",
    "    selected_data = []\n",
    "    def select_data(**kwargs):\n",
    "        selected_data.clear()\n",
    "        for key in kwargs:\n",
    "            if kwargs[key] is True:\n",
    "                selected_data.append(key)\n",
    "                \n",
    "    out = widgets.interactive_output(select_data, arg_dict)\n",
    "    display(ui, out)\n",
    "    \n",
    "    # messages in case the user wishes to run the I_MC measurer\n",
    "    print('\\033[1m'+\"\\nThis message only applies in case you wish to compute the I_MC measure \"+'\\033[0m')\n",
    "    print(\"\\nPlease make sure :\")\n",
    "    print(\"1. To build the parallel_enum project inside the current folder\")\n",
    "    print(\"2. that the file text_ui created by parallel_enum is located in /parallel_enum/build/\")\n",
    "    print('\\033[91m'+'For additional instructions regarding the parallel_enum algorithm, please visit: '+'\\033[0m')\n",
    "    link = widgets.HTML(value=\"<a style='color:red;' target='_blank' rel='noopener noreferrer' href='https://github.com/veluca93/parallel_enum'>parallel_enum github</a>\")\n",
    "    display(link)\n",
    "    \n",
    "    # once the button is clicked the function of runMeasurers is called and the users input will be passed on\n",
    "    button = widgets.Button(description='Proceed',disabled=False,button_style='success',tooltip='Click me',icon='check')\n",
    "    output = widgets.Output()\n",
    "    display(button, output)\n",
    "    \n",
    "    def on_button_clicked(b): \n",
    "        with output:\n",
    "            runMeasurers(databasesNamesToRun,IterationsNum,measurments,selected_data,singleIteration)\n",
    "\n",
    "    button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWelcome to the inconsistency measurer\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the databases you wish to compute the measures on (seperated by ',')\n",
      "The databases included are: Adult,Airport,Flight,Food,Hospital,Stock,Tax,Voters\n",
      " Stock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you wish to run a simulation that introduces random violations in the database? [y/n]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a77ef54eee43b3b72177f8599428a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<i>Default value is: y</i>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please specify the number of iterations of the simulation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfe0a67b8854a90a9f5a49025320ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<i>Default value is: 100</i>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please choose the measures you wish to compute: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726e0182495744789936c14898b5961a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='I_D'), Checkbox(value=False, description='I_MI'), Checkbox(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d67161ff971464f8f62421fae8202ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "This message only applies in case you wish to compute the I_MC measure \u001b[0m\n",
      "\n",
      "Please make sure :\n",
      "1. To build the parallel_enum project inside the current folder\n",
      "2. that the file text_ui created by parallel_enum is located in /parallel_enum/build/\n",
      "\u001b[91mFor additional instructions regarding the parallel_enum algorithm, please visit: \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca549118e0a54779a7b9c6f974abff06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<a style='color:red;' target='_blank' rel='noopener noreferrer' href='https://github.com/veluca93/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981f0b094eb449bda65874afd687f9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Proceed', icon='check', style=ButtonStyle(), tooltip='Click me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4654f396df44d693299d66b815d008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HelloNewUser()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
